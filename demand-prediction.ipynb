{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os.path\n",
    "from fastai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *\n",
    "PATH=Path('data')\n",
    "\n",
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")\n",
    "train = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ru_vecs = ft.load_model('data/wiki.ru.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vecs(lang, ft_vecs):\n",
    "    vecd = {w:ft_vecs.get_word_vector(w) for w in ft_vecs.get_words()}\n",
    "    pickle.dump(vecd, open(PATH/f'wiki.{lang}.pkl', 'wb'))\n",
    "    return vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ru_vecd = get_vecs('ru', ru_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ru_vecd = pickle.load(open(PATH/f'wiki.ru.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1888423"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_words = ru_vecs.get_words(include_freq=True)\n",
    "ft_word_dict = {k:v for k,v in zip(*ft_words)}\n",
    "ft_words = sorted(ft_word_dict.keys(), key=lambda x: ft_word_dict[x])\n",
    "len(ft_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_ru_vec = len(ru_vecd[','])\n",
    "dim_ru_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.003615052, 0.29542154)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_vecs = np.stack(list(ru_vecd.values()))\n",
    "ru_vecs.mean(), ru_vecs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test), len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning CSV into lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo a '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(\"[()]\", \" \", \"foo(a)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#df = pd.DataFrame(columns=['text', \"probability\"])\n",
    "#dict = {} \n",
    "text = []\n",
    "probability = []\n",
    "for i, r in train.iterrows():\n",
    "    t = f'{r.region} {r.city} {r.parent_category_name} {r.category_name} {r.param_1} {r.param_2} {r.param_3} {r.title} {r.description} {r.price} {r.item_seq_number} {r.user_type} {\"yes\" if r.image else \"no\"}'\n",
    "    #t = f'{r.description}'\n",
    "    p = r.deal_probability\n",
    "    text.append(re.sub(\"[()]\", \" \", t))\n",
    "    probability.append(p)\n",
    "    #df.loc[len(df)] = [text, probability]\n",
    "    if i % 100000 == 0: print(i)\n",
    "    \n",
    "#train_processed = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(text, open('data/text.pkl', 'wb'))\n",
    "pickle.dump(probability, open('data/probability.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = pickle.load(open('data/text.pkl', 'rb'))\n",
    "probability = pickle.load(open('data/probability.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 76 ms, sys: 368 ms, total: 444 ms\n",
      "Wall time: 4.41 s\n"
     ]
    }
   ],
   "source": [
    "%time text_tok = Tokenizer.proc_all_mp(partition_by_cores(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['свердловская',\n",
       " 'область',\n",
       " 'екатеринбург',\n",
       " 'личные',\n",
       " 'вещи',\n",
       " 'товары',\n",
       " 'для',\n",
       " 'детей',\n",
       " 'и',\n",
       " 'игрушки',\n",
       " 'постельные',\n",
       " 'принадлежности',\n",
       " 'nan',\n",
       " 'nan',\n",
       " 'кокоби',\n",
       " 'кокон',\n",
       " 'для',\n",
       " 'сна',\n",
       " 'кокон',\n",
       " 'для',\n",
       " 'сна',\n",
       " 'малыша,пользовались',\n",
       " 'меньше',\n",
       " 'месяца.цвет',\n",
       " 'серый',\n",
       " '400.0',\n",
       " '2',\n",
       " 'private',\n",
       " 'yes']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101.0, 101.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile([len(o) for o in text_tok], 90), np.percentile([len(o) for o in text_tok], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep = np.array([len(o) < 101 for o in text_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_tok = np.array(text_tok)[keep]\n",
    "probability = np.array(probability)[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(text_tok, open('data/text_tok.pkl', 'wb'))\n",
    "pickle.dump(probability, open('data/probability_k.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_tok=pickle.load(open('data/text_tok.pkl', 'rb'))\n",
    "probability=pickle.load(open('data/probability_k.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4499, 4499)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probability), len(text_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toks2ids(tok, pre):\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common(40000)]\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    itos.insert(4, 'nan')\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([stoi[o] for o in p] + [2]) for p in tok])\n",
    "    np.save(f'data/tmp_{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(f'data/tmp_{pre}_itos.pkl', 'wb'))\n",
    "    return ids, itos, stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_ids, text_itos, text_stoi = toks2ids(text_tok, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_ids(pre):\n",
    "    ids = np.load(f'data/tmp_{pre}_ids.npy')\n",
    "    itos = pickle.load(open(f'data/tmp_{pre}_itos.pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k, v in enumerate(itos)})\n",
    "    return ids, itos, stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_ids, text_itos, text_stoi = load_ids('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4499, 4499)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probability), len(text_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4017, 482)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(text_ids)) > 0.1\n",
    "trn = text_ids[trn_keep]\n",
    "trn_y = probability[trn_keep]\n",
    "val = text_ids[~trn_keep]\n",
    "val_y = probability[~trn_keep]\n",
    "len(trn), len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ list([76, 12, 120, 17, 16, 51, 11, 79, 7, 61, 615, 599, 6, 6, 8026, 2795, 11, 3503, 2795, 11, 3503, 8027, 1038, 8028, 1180, 154, 29, 9, 8, 2]),\n",
       "       list([93, 12, 157, 11, 35, 7, 38, 82, 7, 111, 109, 6, 6, 2796, 11, 694, 2796, 11, 694, 5, 138, 8029, 23, 8030, 226, 247, 9, 8, 2]),\n",
       "       list([90, 12, 174, 39, 44, 282, 7, 232, 232, 5, 21, 1181, 7, 1586, 18, 1587, 1783, 6, 6, 1784, 8031, 14, 58, 52, 5, 1588, 8032, 23, 1586, 1587, 5, 21, 1039, 28, 573, 8033, 5, 574, 311, 2797, 1785, 13, 20, 112, 396, 113, 9, 8, 2]),\n",
       "       ...,\n",
       "       list([150, 27, 254, 100, 7, 67, 245, 7, 67, 711, 7, 741, 6, 6, 23144, 1157, 23145, 23146, 8023, 14, 64, 23147, 85, 23148, 13, 20, 11, 748, 1445, 23149, 300, 23150, 13, 20, 7769, 810, 23151, 87, 23152, 23153, 23154, 7, 23155, 138, 23156, 23157, 19, 2024, 23158, 23159, 11, 3496, 7, 23160, 8023, 249, 7991, 512, 182, 23161, 23162, 778, 23163, 9, 8, 2]),\n",
       "       list([257, 313, 17, 16, 10, 5, 15, 5, 24, 33, 10, 46, 10, 129, 115, 108, 119, 119, 5, 433, 449, 34, 950, 57, 2650, 26, 8, 2]),\n",
       "       list([131, 27, 1386, 17, 16, 51, 11, 79, 7, 61, 51, 11, 491, 6, 6, 8024, 8025, 292, 103, 22, 8024, 8025, 292, 103, 23164, 161, 23165, 26, 8, 2])], dtype=object)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12789,  0.     ,  0.43177, ...,  0.08065,  0.     ,  0.     ])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x, self.y = x, y\n",
    "    def __getitem__(self, idx): return A(self.x[idx], [int(self.y[idx]*1000)])\n",
    "    def __len__(self): return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0.2312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trn_y = trn.iloc[:,-1]\n",
    "#val_y = val.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trn = trn.iloc[:, :-1]\n",
    "#val = val.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_ds = Seq2SeqDataset(trn, trn_y)\n",
    "val_ds = Seq2SeqDataset(val, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_samp = SortishSampler(trn, key=lambda x: len(trn[x]), bs=batch_size)\n",
    "val_samp = SortSampler(val, key=lambda x: len(val[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds, batch_size, transpose = True, transpose_y=True, num_workers=1, pad_idx=1, pre_pad=False,\n",
    "                   sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, int(batch_size*1.6), transpose=True, transpose_y=True, num_workers=1, pad_idx = 1,\n",
    "                pre_pad = False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx = 1)\n",
    "    wgts = emb.weight.data # jeremy: this is a tensor\n",
    "    miss = []\n",
    "    for i, w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w] * 3) # jeremy: our stddev is 0.3, so mul by 3 to get to 1.0\n",
    "        except: miss.append(w)\n",
    "    print(len(miss), miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_hidden_features, num_layers = 16, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, num_hidden_features, out_sequence_length, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.num_layers, self.num_hidden_features, self.out_sequence_length = num_layers, num_hidden_features, out_sequence_length\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, num_hidden_features, num_layers=num_layers, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(num_hidden_features, em_sz_dec, bias=False)\n",
    "        \n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=num_layers, dropout=0.1)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        sequence_length, batch_size = inp.size()\n",
    "        h = self.initHidden(batch_size)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "        \n",
    "        dec_inp = V(torch.zeros(batch_size).long())\n",
    "        res = []\n",
    "        \n",
    "        for i in range(self.out_sequence_length):\n",
    "            # dec_inp: the previous word we translated\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0) # treat this as a sequence of length=1\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, batch_size): return V(torch.zeros(self.num_layers, batch_size, self.num_hidden_features))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    sequence_length, batch_size = target.size()\n",
    "    sequence_length_in, batch_size_in, nc = input.size()\n",
    "    # add some padding, because our sequence length might be different \n",
    "    if sequence_length > sequence_length_in: input = F.pad(input, (0, 0, 0, 0, 0, sequence_length-sequence_length_in))\n",
    "    input = input[:sequence_length]\n",
    "    return F.cross_entropy(input.view(-1, nc), target.view(-1)) \n",
    "    #return F.mse_loss(input.view(-1, nc), target.view(-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 23166)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_ru_vec, len(text_itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10080 ['t_up', '2', '4', '1', 'tk_rep']\n",
      "4499 [0.80323, 0.0, 0.80323, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN(ru_vecd, text_itos, dim_ru_vec, ru_vecd, probability, 1, num_hidden_features, 101)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learn.lr_find()\n",
    "#learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 10e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#??learn.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4021c7aa8a94dc3b33df2a36eb061a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                            \n",
      "    0      6.927715   3.566764  \n",
      "    1      4.642829   3.06099                             \n",
      "    2      3.64458    2.650518                            \n",
      "    3      3.106591   2.632878                            \n",
      "    4      2.779962   2.595338                            \n",
      "    5      2.652441   2.601975                            \n",
      "    6      2.53254    2.566906                            \n",
      "    7      2.472813   2.550843                            \n",
      "    8      2.414332   2.532799                            \n",
      "    9      2.406546   2.547247                            \n",
      "    10     2.353711   2.546311                            \n",
      "    11     2.33129    2.548141                            \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 2.54814])]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(learning_rate, 1, cycle_len=12, use_clr=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"initial.m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.load(\"initial.m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
